Reinforcement Learning from Human Feedback (RLHF)
Direct Preference Optimization DPO (Bonus Topic)
DPO (Direct Policy Optimization) vs. RLHF (Reinforcement Learning from Human Feedback): Understanding the Differences
Parameter Efficient Fine-Tuning (PEFT)
